{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# from config import db_password\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) # create a non-dest. copy\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "\n",
    "def function_name():\n",
    "    # Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv')\n",
    "    ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "    # Open and read the Wikipedia data JSON file.\n",
    "    with open(f'{file_dir}wikipedia-movies.json', mode = \"r\") as file:\n",
    "            wiki_movies_raw = json.load(file)\n",
    "    \n",
    "    # 3. Write a list comprehension to filter out TV shows. # \"Television series\", \"No. of episodes\", \"No. of seasons\"\n",
    "    \n",
    "    [\n",
    "        movie for movie in wiki_movies_raw\n",
    "        if \"Television series\" not in movie\n",
    "        and \"No. of episodes\" not in movie\n",
    "        and \"No. of seasons\" not in movie\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # 4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "\n",
    "    # 5. Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "\n",
    "\n",
    "    # 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "try: wiki_movies_df[\"imdb_id\"] = wiki_movies_df[\"imdb_link\"].str.extract(r\"(tt\\d{7})\")\n",
    "        \n",
    "        \n",
    "except:\n",
    "        print(\"couldn't extract imdb_link information\")\n",
    "        \n",
    "try: wiki_movies_df.drop_duplicates(subset = \"imdb_id\", inplace = True)\n",
    "\n",
    "except:\n",
    "        print(\"couldn't get rid of duplicates\")\n",
    "\n",
    "    #  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 8. Create a variable that will hold the non-null values from the “Box office” column.\n",
    "\n",
    "    \n",
    "    # 9. Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "    \n",
    "\n",
    "    # 10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "   \n",
    "    # 11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "    \n",
    "\n",
    "    # 12. Add the parse_dollars function.\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 13. Clean the box office column in the wiki_movies_df DataFrame.\n",
    "\n",
    "    \n",
    "    # 14. Clean the budget column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 15. Clean the release date column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 16. Clean the running time column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "    # Return three variables. The first is the wiki_movies_df DataFrame\n",
    "    \n",
    "    return wiki_movies_df, kaggle_metadata, ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the Wikipedia data JSON file.\n",
    "file_dir = \"C:/Users/15124/Desktop/Class_work/\"\n",
    "    \n",
    "with open(f'{file_dir}wikipedia-movies.json', mode = \"r\") as file:\n",
    "    wiki_movies_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie(movie):\n",
    "    movie = dict(movie)\n",
    "    [movie for movie in wiki_movies_raw\n",
    "     if \"Television series\" not in movie\n",
    "     and \"No. of episodes\" not in movie\n",
    "     and \"No. of seasons not in movie\"]\n",
    "    \n",
    "    return movie\n",
    "    \n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "\n",
    "wiki_movies_df = pd.DataFrame(clean_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7304"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "try: wiki_movies_df[\"imdb_id\"] = wiki_movies_df[\"imdb_link\"].str.extract(r\"(tt\\d{7})\")\n",
    "        \n",
    "        \n",
    "except:\n",
    "        print(\"couldn't extract imdb_link information\")\n",
    "len(wiki_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7050"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 CONT.\n",
    "try: wiki_movies_df.drop_duplicates(subset = \"imdb_id\", inplace = True)\n",
    "\n",
    "except:\n",
    "        print(\"couldn't get rid of duplicates\")\n",
    "len(wiki_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['url', 1],\n",
       " ['year', 1],\n",
       " ['imdb_link', 1],\n",
       " ['title', 6],\n",
       " ['Directed by', 19],\n",
       " ['Produced by', 374],\n",
       " ['Screenplay by', 4743],\n",
       " ['Story by', 6053],\n",
       " ['Based on', 4868],\n",
       " ['Starring', 198],\n",
       " ['Narrated by', 6768],\n",
       " ['Music by', 609],\n",
       " ['Cinematography', 707],\n",
       " ['Edited by', 711],\n",
       " ['Productioncompany ', 2548],\n",
       " ['Distributed by', 511],\n",
       " ['Release date', 204],\n",
       " ['Running time', 152],\n",
       " ['Country', 396],\n",
       " ['Language', 252],\n",
       " ['Budget', 2312],\n",
       " ['Box office', 1565],\n",
       " ['Written by', 2505],\n",
       " ['Genre', 6933],\n",
       " ['Theme music composer', 6983],\n",
       " ['Country of origin', 6898],\n",
       " ['Original language(s)', 6892],\n",
       " ['Producer(s)', 6894],\n",
       " ['Editor(s)', 6904],\n",
       " ['Production company(s)', 6919],\n",
       " ['Original network', 6925],\n",
       " ['Original release', 6891],\n",
       " ['Productioncompanies ', 6327],\n",
       " ['Executive producer(s)', 6953],\n",
       " ['Production location(s)', 7003],\n",
       " ['Distributor', 6912],\n",
       " ['Picture format', 6986],\n",
       " ['Audio format', 6989],\n",
       " ['Voices of', 7048],\n",
       " ['Followed by', 7039],\n",
       " ['Composer(s)', 7042],\n",
       " ['Created by', 7039],\n",
       " ['Preceded by', 7038],\n",
       " ['Author', 7046],\n",
       " ['Publisher', 7046],\n",
       " ['Publication date', 7046],\n",
       " ['Media type', 7047],\n",
       " ['Pages', 7048],\n",
       " ['ISBN', 7048],\n",
       " ['OCLC', 7048],\n",
       " ['LC Class', 7049],\n",
       " ['Cover artist', 7049],\n",
       " ['Series', 7049],\n",
       " ['Set in', 7049],\n",
       " ['Adaptation by', 7048],\n",
       " ['Suggested by', 7049],\n",
       " ['Biographical data', 7050],\n",
       " ['Born', 7050],\n",
       " ['Died', 7050],\n",
       " ['Resting place', 7050],\n",
       " ['Occupation', 7050],\n",
       " ['Years active', 7050],\n",
       " ['Spouse(s)', 7050],\n",
       " ['Children', 7050],\n",
       " ['Parent(s)', 7050],\n",
       " ['Genres', 7050],\n",
       " ['Instruments', 7050],\n",
       " ['Labels', 7050],\n",
       " ['Website', 7050],\n",
       " ['Traditional', 7045],\n",
       " ['Mandarin', 7046],\n",
       " ['Type', 7050],\n",
       " ['Industry', 7050],\n",
       " ['Fate', 7050],\n",
       " ['Founded', 7050],\n",
       " ['Founder', 7050],\n",
       " ['Headquarters', 7050],\n",
       " ['Parent', 7050],\n",
       " ['Released', 7046],\n",
       " ['Recorded', 7047],\n",
       " ['Venue', 7049],\n",
       " ['Length', 7047],\n",
       " ['Label', 7046],\n",
       " ['Director', 7048],\n",
       " ['Producer', 7047],\n",
       " ['Area', 7049],\n",
       " ['Coordinates', 7049],\n",
       " ['Status', 7049],\n",
       " ['Opening date', 7049],\n",
       " ['Closing date', 7049],\n",
       " ['Replaced', 7049],\n",
       " ['Replaced by', 7049],\n",
       " ['Name', 7049],\n",
       " ['Attraction type', 7049],\n",
       " ['Music', 7049],\n",
       " ['Duration', 7049],\n",
       " ['Simplified Chinese', 7050],\n",
       " ['Traditional Chinese', 7050],\n",
       " ['Hanyu Pinyin', 7050],\n",
       " ['Literal meaning', 7050],\n",
       " ['Transcriptions', 7050],\n",
       " ['Bopomofo', 7050],\n",
       " ['Gwoyeu Romatzyh', 7050],\n",
       " ['Wade–Giles', 7050],\n",
       " ['IPA', 7050],\n",
       " ['Yale Romanization', 7050],\n",
       " ['Jyutping', 7050],\n",
       " ['Hokkien POJ', 7050],\n",
       " ['Also known as', 7049],\n",
       " ['Animation by', 7048],\n",
       " ['Color process', 7049],\n",
       " ['Engine(s)', 7050],\n",
       " ['Genre(s)', 7050],\n",
       " ['Actor control', 7050],\n",
       " ['Production company', 7050],\n",
       " ['Release(s)', 7050],\n",
       " ['Format(s)', 7050],\n",
       " ['Simplified', 7046],\n",
       " ['Characters', 7049],\n",
       " ['Date premiered', 7049],\n",
       " ['Place premiered', 7049],\n",
       " ['Setting', 7049],\n",
       " ['Original language', 7049],\n",
       " ['Subject', 7049],\n",
       " ['Published', 7050],\n",
       " ['Dewey Decimal', 7050],\n",
       " ['Text', 7049],\n",
       " ['Illustrator', 7050],\n",
       " ['Original title', 7049],\n",
       " ['Published in English', 7050],\n",
       " ['French', 7049],\n",
       " ['Nationality', 7049],\n",
       " ['Portrayed by', 7049],\n",
       " ['Alias', 7049],\n",
       " ['Species', 7049],\n",
       " ['Gender', 7049],\n",
       " ['Family', 7049],\n",
       " ['Alma mater', 7049],\n",
       " ['Novel(s)', 7050],\n",
       " ['Comics', 7050],\n",
       " ['Film(s)', 7050],\n",
       " ['Screen story by', 7049],\n",
       " ['Hangul', 7048],\n",
       " ['Revised Romanization', 7048],\n",
       " ['McCune–Reischauer', 7048],\n",
       " ['Developer(s)', 7050],\n",
       " ['Publisher(s)', 7050],\n",
       " ['Designer(s)', 7050],\n",
       " ['Programmer(s)', 7050],\n",
       " ['Artist(s)', 7050],\n",
       " ['Writer(s)', 7050],\n",
       " ['Engine', 7050],\n",
       " ['Platform(s)', 7050],\n",
       " ['Release', 7050],\n",
       " ['Mode(s)', 7050],\n",
       " ['Japanese', 7046],\n",
       " ['Hepburn', 7046],\n",
       " ['Literally', 7047],\n",
       " ['Cantonese', 7049],\n",
       " ['Full name', 7050],\n",
       " ['Height', 7050],\n",
       " ['Seasons', 7050],\n",
       " ['Chinese', 7049],\n",
       " ['Other names', 7050],\n",
       " ['Relatives', 7050],\n",
       " ['Yiddish', 7049],\n",
       " ['Formerly', 7050],\n",
       " ['Key people', 7050],\n",
       " ['Total assets', 7050],\n",
       " ['Owner', 7050],\n",
       " ['Number of employees', 7050],\n",
       " ['Divisions', 7050],\n",
       " ['Subsidiaries', 7050],\n",
       " ['Arabic', 7048],\n",
       " ['Romanized', 7048],\n",
       " ['Predecessor', 7050],\n",
       " ['Founders', 7050],\n",
       " ['Area served', 7050],\n",
       " ['Products', 7050],\n",
       " ['Services', 7050],\n",
       " ['Russian', 7049],\n",
       " ['Hebrew', 7049],\n",
       " ['Revenue', 7050],\n",
       " ['Operating income', 7050],\n",
       " ['Polish', 7049],\n",
       " ['imdb_id', 1]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using list comprehension to get list of columns that contain null values\n",
    "[[column, wiki_movies_df[column].isnull().sum()] for column in wiki_movies_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7049\n",
       "True        1\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df[\"url\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wiki_movies_df[\"url\"].isnull() == \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "\n",
    "wiki_columns_keep =[column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.99]\n",
    "\n",
    "wiki_movies_df = wiki_movies_df[wiki_columns_keep]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          $21.4 million\n",
       "1           $2.7 million\n",
       "2            $57,718,089\n",
       "3             $7,331,647\n",
       "4       $6,939,946 (USA)\n",
       "              ...       \n",
       "7298       $19.4 million\n",
       "7299       $41.9 million\n",
       "7300       $76.1 million\n",
       "7301       $38.4 million\n",
       "7302        $5.5 million\n",
       "Name: Box office, Length: 5485, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Create a variable that will hold the non-null values from the “Box office” column.\n",
    "box_office = wiki_movies_df[\"Box office\"]\n",
    "box_office\n",
    "\n",
    "# 7,050\n",
    "\n",
    "box_office = wiki_movies_df[\"Box office\"].dropna()\n",
    "box_office\n",
    "\n",
    "# 5,485 dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          $21.4 million\n",
       "1           $2.7 million\n",
       "2            $57,718,089\n",
       "3             $7,331,647\n",
       "4       $6,939,946 (USA)\n",
       "              ...       \n",
       "7298       $19.4 million\n",
       "7299       $41.9 million\n",
       "7300       $76.1 million\n",
       "7301       $38.4 million\n",
       "7302        $5.5 million\n",
       "Name: Box office, Length: 5485, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "box_office[box_office.map(lambda x: type(x) != str)]\n",
    "\n",
    "box_office = box_office.apply(lambda x: ''.join(x) if type(x) ==list else x)\n",
    "box_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           # 10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "\n",
    "# 1. A dollar sign \n",
    "\"\\$\"\n",
    "\n",
    "# 2. An arbitary (but non-zero) number of digits\n",
    "\"\\$\\d+\"\n",
    "\n",
    "# 3. An optional decimal point \\\\\\ since the decimal point is optional, add a QUESTION Mark (?) after it\n",
    "\"\\$\\d+\\.?\"\n",
    "\n",
    "# 4. An arbitary (but possibly zero) number of more digits \n",
    "\"\\$\\d+\\.?\\d*\"\n",
    "\n",
    "# 5. A space (maybe more than one)\n",
    "\"\\$\\d+\\.?\\d*\\s*\"\n",
    "\n",
    "# 6. the world \"million\" or \"billion\"\n",
    "\"\\$\\d+\\.?\\d*\\s*\\[mb]illion\"\n",
    "\n",
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              # 11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "# 1. A dollar sign \n",
    "\"\\$\"\n",
    "\n",
    "# 2. A group of one to three digits\n",
    "\"\\$\\d{1,3}\"\n",
    "\n",
    "# 3. At least one group starting with a comma and followed by *exactly* three digits.\n",
    "\"\\$\\d{1,3}(?:,\\d{3})+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Add the parse_dollars function.\n",
    "\n",
    "# convert all the strings to floats, multiply by the right amount, and return the value.\n",
    "\n",
    "def parse_dollars(s):\n",
    "    # If s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "    \n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags= re.IGNORECASE):\n",
    "        \n",
    "        # remove dollar sign and \"million\"\n",
    "        s= re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "        \n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "        \n",
    "        # return value\n",
    "        return value\n",
    "    \n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags= re.IGNORECASE):    \n",
    "        \n",
    "        # remove dollar sign and \"billion\"\n",
    "        s= re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "        \n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "        \n",
    "        # return value \n",
    "        return value\n",
    "        \n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags= re.IGNORECASE):\n",
    "    \n",
    "        # remove dollar sign and commas\n",
    "        s= re.sub('\\$|,', \"\", s)\n",
    "        \n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "        \n",
    "        # return value\n",
    "        return value\n",
    "        \n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Clean the box office column in the wiki_movies_df DataFrame.\n",
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
    "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "\n",
    "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}| {form_two})', flags= re.IGNORECASE)[0].apply(parse_dollars)\n",
    "# No longer need the Box Office column, so we'll drop it.\n",
    "wiki_movies_df.drop(\"Box office\", axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Clean the budget column in the wiki_movies_df DataFrame.\n",
    "\n",
    "# Create budget variable \n",
    "\n",
    "budget = wiki_movies_df[\"Budget\"].dropna()\n",
    "\n",
    "# convert any lists to strings\n",
    "\n",
    "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "# remove any values between a dollar sign ($) and a hyphen (-) | for budgets given in RANGES\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE)\n",
    "\n",
    "# budget[~matches_form_one & ~matches_form_two] # remember, ~ means NOT, and \"&\" means AND ##\n",
    "\n",
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '') # replacing citations with \"\". the \\s* accounts for possible spaces.\n",
    "budget[~matches_form_one & ~matches_form_two]\n",
    "\n",
    "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "\n",
    "# now we drop the original Budget column\n",
    "\n",
    "wiki_movies_df.drop('Budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [July 11, 1990, (, 1990-07-11, )]\n",
       "1       [May 17, 1990, (, 1990-05-17, ), (Cannes Film ...\n",
       "2                     [August 10, 1990, (, 1990-08-10, )]\n",
       "3                   [December 25, 1990, (, 1990-12-25, )]\n",
       "4                                       December 19, 1990\n",
       "                              ...                        \n",
       "7299    [December 25, 2018, (, 2018-12-25, ), (United ...\n",
       "7300    [December 11, 2018, (, 2018-12-11, ), (, Samue...\n",
       "7301    [November 8, 2018, (, 2018-11-08, ), (, AFI Fe...\n",
       "7302    [August 31, 2018, (, 2018-08-31, ), (, Telluri...\n",
       "7303                 [28 December 2018, (, 2018-12-28, )]\n",
       "Name: Release date, Length: 7050, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df[\"Release date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1990-07-11\n",
       "1      1990-05-17\n",
       "2      1990-08-10\n",
       "3      1990-12-25\n",
       "4      1990-12-19\n",
       "          ...    \n",
       "7299   2018-12-25\n",
       "7300   2018-12-11\n",
       "7301   2018-01-01\n",
       "7302   2018-08-31\n",
       "7303   2018-12-01\n",
       "Name: release_date, Length: 7050, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df[\"release_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Clean the release date column in the wiki_movies_df DataFrame.\n",
    "\n",
    "# make a variable that holds the non-null values of Release date in the Dataframe, converting lists to strings.\n",
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "# 1. Full month name, one- to two-digit day, four-digit year (i.e. January 1, 2000)\n",
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "\n",
    "# 2. Four-digit year, two-digit month, two-digit dya, with any seperator (i.e. 2000-01-01)\n",
    "date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "\n",
    "# 3. Full month name, four-digit year (i.e. January 2000)\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "\n",
    "# 4. Four-digit year\n",
    "date_form_four = r'\\d{4}'\n",
    "\n",
    "\n",
    "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "\n",
    "# can drop \"Release date\" column now (replaced with \"release_date\")\n",
    "wiki_movies_df.drop(\"Release date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Clean the running time column in the wiki_movies_df DataFrame.\n",
    "\n",
    "# make a variable that holds the non-null values of Release date in the Dataframe, coverting lists to strings.\n",
    "running_time = wiki_movies_df[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(wiki_movies_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # 3. Write a list comprehension to filter out TV shows. # \"Television series\", \"No. of episodes\", \"No. of seasons\"\n",
    "\n",
    "wiki_movies= [\n",
    "    movie for movie in wiki_movies_raw\n",
    "    if \"Television series\" not in movie\n",
    "    and \"No. of episodes\" not in movie\n",
    "    and \"No. of seasons\" not in movie\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_movie(movie):\n",
    "#     movie = dict(movie)\n",
    "#     alt_titles = {}\n",
    "#     for key in [\"Also known as\", \"Arabic\", \"Cantonese\", \"Chinese\", \"French\", \n",
    "#                 \"Hangul\", \"Hebrew\", \"Hepburn\", \"Japanese\", \"Literally\", \"Mandarin\",\n",
    "#                 \"McCune–Reischauer\", \"Original title\", \"Polish\",  \"Revised Romanization\", \n",
    "#                 \"Romanized\", \"Russian\", \"Simplified\", \"Traditional\", \"Yiddish\"]:\n",
    "#         if key in movie:\n",
    "#             alt_titles[key] = movie[key]\n",
    "#             movie.pop(key)\n",
    "#     if len(alt_titles) > 0:\n",
    "#         movie[\"alt_titles\"] = alt_titles\n",
    "        \n",
    "#     return movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'year',\n",
       " 'imdb_link',\n",
       " 'title',\n",
       " 'Directed by',\n",
       " 'Produced by',\n",
       " 'Screenplay by',\n",
       " 'Story by',\n",
       " 'Based on',\n",
       " 'Starring',\n",
       " 'Narrated by',\n",
       " 'Music by',\n",
       " 'Cinematography',\n",
       " 'Edited by',\n",
       " 'Productioncompany ',\n",
       " 'Distributed by',\n",
       " 'Release date',\n",
       " 'Running time',\n",
       " 'Country',\n",
       " 'Language',\n",
       " 'Budget',\n",
       " 'Box office',\n",
       " 'Written by',\n",
       " 'Genre',\n",
       " 'Theme music composer',\n",
       " 'Country of origin',\n",
       " 'Original language(s)',\n",
       " 'Producer(s)',\n",
       " 'Editor(s)',\n",
       " 'Production company(s)',\n",
       " 'Original network',\n",
       " 'Original release',\n",
       " 'Productioncompanies ',\n",
       " 'Executive producer(s)',\n",
       " 'Production location(s)',\n",
       " 'Distributor',\n",
       " 'Picture format',\n",
       " 'Audio format',\n",
       " 'Voices of',\n",
       " 'Followed by',\n",
       " 'Composer(s)',\n",
       " 'Created by',\n",
       " 'Also known as',\n",
       " 'Opening theme',\n",
       " 'No. of episodes',\n",
       " 'Preceded by',\n",
       " 'Author',\n",
       " 'Publisher',\n",
       " 'Publication date',\n",
       " 'Media type',\n",
       " 'Pages',\n",
       " 'ISBN',\n",
       " 'OCLC',\n",
       " 'LC Class',\n",
       " 'Cover artist',\n",
       " 'Series',\n",
       " 'Set in',\n",
       " 'Adaptation by',\n",
       " 'Suggested by',\n",
       " 'Biographical data',\n",
       " 'Born',\n",
       " 'Died',\n",
       " 'Resting place',\n",
       " 'Occupation',\n",
       " 'Years active',\n",
       " 'Spouse(s)',\n",
       " 'Children',\n",
       " 'Parent(s)',\n",
       " 'Genres',\n",
       " 'Instruments',\n",
       " 'Labels',\n",
       " 'Website',\n",
       " 'Traditional',\n",
       " 'Mandarin',\n",
       " 'Type',\n",
       " 'Industry',\n",
       " 'Fate',\n",
       " 'Founded',\n",
       " 'Founder',\n",
       " 'Headquarters',\n",
       " 'Parent',\n",
       " 'Released',\n",
       " 'Recorded',\n",
       " 'Venue',\n",
       " 'Length',\n",
       " 'Label',\n",
       " 'Director',\n",
       " 'Producer',\n",
       " 'Area',\n",
       " 'Coordinates',\n",
       " 'Status',\n",
       " 'Opening date',\n",
       " 'Closing date',\n",
       " 'Replaced',\n",
       " 'Replaced by',\n",
       " 'Name',\n",
       " 'Attraction type',\n",
       " 'Music',\n",
       " 'Duration',\n",
       " 'Simplified Chinese',\n",
       " 'Traditional Chinese',\n",
       " 'Hanyu Pinyin',\n",
       " 'Literal meaning',\n",
       " 'Transcriptions',\n",
       " 'Bopomofo',\n",
       " 'Gwoyeu Romatzyh',\n",
       " 'Wade–Giles',\n",
       " 'IPA',\n",
       " 'Yale Romanization',\n",
       " 'Jyutping',\n",
       " 'Hokkien POJ',\n",
       " 'Animation by',\n",
       " 'Color process',\n",
       " 'Engine(s)',\n",
       " 'Genre(s)',\n",
       " 'Actor control',\n",
       " 'Production company',\n",
       " 'Release(s)',\n",
       " 'Format(s)',\n",
       " 'Simplified',\n",
       " 'Characters',\n",
       " 'Date premiered',\n",
       " 'Place premiered',\n",
       " 'Setting',\n",
       " 'Original language',\n",
       " 'Subject',\n",
       " 'Published',\n",
       " 'Dewey Decimal',\n",
       " 'Text',\n",
       " 'Illustrator',\n",
       " 'Original title',\n",
       " 'Published in English',\n",
       " 'French',\n",
       " 'Developed by',\n",
       " 'Ending theme',\n",
       " 'No. of seasons',\n",
       " 'Nationality',\n",
       " 'Portrayed by',\n",
       " 'Alias',\n",
       " 'Species',\n",
       " 'Gender',\n",
       " 'Family',\n",
       " 'Alma mater',\n",
       " 'Camera setup',\n",
       " 'Novel(s)',\n",
       " 'Comics',\n",
       " 'Film(s)',\n",
       " 'Screen story by',\n",
       " 'Hangul',\n",
       " 'Revised Romanization',\n",
       " 'McCune–Reischauer',\n",
       " 'Developer(s)',\n",
       " 'Publisher(s)',\n",
       " 'Designer(s)',\n",
       " 'Programmer(s)',\n",
       " 'Artist(s)',\n",
       " 'Writer(s)',\n",
       " 'Engine',\n",
       " 'Platform(s)',\n",
       " 'Release',\n",
       " 'Mode(s)',\n",
       " 'Original work',\n",
       " 'Television series',\n",
       " 'Japanese',\n",
       " 'Hepburn',\n",
       " 'Literally',\n",
       " 'Cantonese',\n",
       " 'Full name',\n",
       " 'Height',\n",
       " 'Seasons',\n",
       " 'Chinese',\n",
       " 'Other names',\n",
       " 'Relatives',\n",
       " 'Yiddish',\n",
       " 'Formerly',\n",
       " 'Key people',\n",
       " 'Total assets',\n",
       " 'Owner',\n",
       " 'Number of employees',\n",
       " 'Divisions',\n",
       " 'Subsidiaries',\n",
       " 'Arabic',\n",
       " 'Romanized',\n",
       " 'Predecessor',\n",
       " 'Founders',\n",
       " 'Area served',\n",
       " 'Products',\n",
       " 'Services',\n",
       " 'Russian',\n",
       " 'Hebrew',\n",
       " 'Revenue',\n",
       " 'Operating income',\n",
       " 'Polish']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "wiki_movies_df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Create the path to your file directory and variables for the three files.\n",
    "file_dir = \n",
    "# The Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia.movies.json'\n",
    "# The Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# The MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Set the three variables equal to the function created in D1.\n",
    "wiki_file, kaggle_file, ratings_file = extract_transform_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Set the wiki_movies_df equal to the wiki_file variable. \n",
    "wiki_movies_df = wiki_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Check that the wiki_movies_df DataFrame looks like this. \n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Check that wiki_movies_df DataFrame columns are correct. \n",
    "wiki_movies_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
